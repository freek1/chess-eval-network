# -*- coding: utf-8 -*-
"""chess-evaluation-prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f9Pm7bNP__PQ0wtn21WlckNG2S_ShSbS
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import re
import matplotlib.pyplot as plt
import random
from tqdm import tqdm
from multiprocessing import  Pool
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.optim as optim
import chess

random.seed(420)
np.random.seed(420)

class Geohotz(nn.Module):
    def __init__(self):
        super(Geohotz, self).__init__()
        self.conv1 = nn.Conv2d(29, 32, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU()
        self.bn1 = nn.BatchNorm2d(32)
        
        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)
        self.relu2 = nn.ReLU()
        self.bn2 = nn.BatchNorm2d(32)
        
        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2)
        self.relu3 = nn.ReLU()
        self.bn3 = nn.BatchNorm2d(64)
        
        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.relu4 = nn.ReLU()
        self.bn4 = nn.BatchNorm2d(64)
        
        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.relu5 = nn.ReLU()
        self.bn5 = nn.BatchNorm2d(64)
        
        self.conv6 = nn.Conv2d(64, 128, kernel_size=3, stride=2)
        self.relu6 = nn.ReLU()
        self.bn6 = nn.BatchNorm2d(128)
        
        self.flatten = nn.Flatten()
        self.dropout = nn.Dropout(0.5)
        self.linear = nn.Linear(128, 1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.bn1(x)
        
        x = self.conv2(x)
        x = self.relu2(x)
        x = self.bn2(x)
        
        x = self.conv3(x)
        x = self.relu3(x)
        x = self.bn3(x)
        
        x = self.conv4(x)
        x = self.relu4(x)
        x = self.bn4(x)
        
        x = self.conv5(x)
        x = self.relu5(x)
        x = self.bn5(x)
        
        x = self.conv6(x)
        x = self.relu6(x)
        x = self.bn6(x)
                
        x = self.flatten(x)
        x = self.dropout(x)
        x = self.linear(x)
        
        return x


class ChessDataset(Dataset):
    def __init__(self, df):
        self.fens = torch.from_numpy(np.array([*map(to_bitboard, df["FEN"])], dtype=np.uint8))
        self.evals = torch.Tensor([[x] for x in df["Normalized Evaluation"]])
        self._len = len(self.evals)

    def __len__(self):
        return self._len

    def __getitem__(self, index):
        return self.fens[index], self.evals[index]


# r1bqk2r/pp2ppbp/2np1np1/8/4P3/2N3P1/PPP1NPBP/R1BQK2R b KQkq - 4 8
def to_bitboard(fen):
    boards = np.zeros((29, 8, 8), dtype=np.uint8)
    board = chess.Board(fen)

    piece_to_layer = {
        'R': 1,
        'N': 2,
        'B': 3,
        'Q': 4,
        'K': 5,
        'P': 6,
        'p': 7,
        'k': 8,
        'q': 9,
        'b': 10,
        'n': 11,
        'r': 12
    }

    piece_to_material = {
        'R': 5,
        'N': 3,
        'B': 3,
        'Q': 9,
        'K': 0,
        'P': 1,
        'p': -1,
        'k': 0,
        'q': -9,
        'b': -3,
        'n': -3,
        'r': -5
    }

    color = bool(board.turn)

    cr = board.castling_rights
    wkcastle = bool(cr & chess.H1)
    wqcastle = bool(cr & chess.A1)
    bkcastle = bool(cr & chess.H8)
    bqcastle = bool(cr & chess.A8)

    boards[0, :, :]  = color
    boards[25, :, :] = wkcastle
    boards[26, :, :] = wqcastle
    boards[27, :, :] = bkcastle
    boards[28, :, :] = bqcastle

    material = 0

    piece_map = board.piece_map()
    for i, p in piece_map.items():
        rank, file = to_square(i)
        piece = p.symbol()
        # Mark the position of the piece on the bitboard
        boards[piece_to_layer[piece], rank, file] = 1
        material += piece_to_material[piece]
        # Attack maps
        for sq in board.attacks(i):
            attack_rank, attack_file = to_square(sq)
            boards[piece_to_layer[piece]+12, attack_rank, attack_file] = 1

    return boards

def to_square(number):
    rank, file = divmod(number, 8)
    return 7 - rank, file

def main():
    bbdf = pd.read_csv('processed_chessData.csv')
    print(bbdf.shape)
    bbdf = bbdf[0:20000]

    l = len(bbdf)
    bbdf = bbdf.sample(frac=1)
    train_df, test_df, cv_df = bbdf[:int(.8 * l)], bbdf[int(.8 * l): int(.9 * l)], bbdf[int(.9 * l):]

    import gc
    gc.collect()

    print('mapping dataset')
    d_train, d_test, d_cv = map(ChessDataset, [train_df, test_df, cv_df])
    
    device = torch.device("mps" if torch.mps.is_available() else "cpu")
    print('device', device)

    # Beeg model
    model = Geohotz().to(device)
    
    params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(model)
    print(params)

    def init_weights(m):
        try:
            nn.init.xavier_uniform_(m.weight)
            m.bias.data.fill_(0.01)
        except Exception:
            return

    model.apply(init_weights)

    # model(next(iter(cv_loader))[0].float())

    cv_loader = DataLoader(dataset=d_cv, batch_size=512, shuffle=False, num_workers=1)
    train_loader = DataLoader(dataset=d_train, batch_size=512, shuffle=True, num_workers=1)
    criterion = nn.MSELoss()
    optimizer = optim.AdamW(model.parameters())

    train_losses = []
    cv_losses = []

    for epoch in range(60):
        model.train()
        running_loss = []
        for data, target in train_loader:
            optimizer.zero_grad()
            data, target = data.to(device), target.to(device)
            y_pred = model(data.float())
            loss = criterion(y_pred, target)
            running_loss.append(loss.item())
            loss.backward()
            optimizer.step()
        train_losses.append(sum(running_loss) / len(running_loss))
        print(f"[TRAIN] epoch: {epoch:5}, loss: {train_losses[-1]:10}", end="\t")

        with torch.no_grad():
            model.eval()
            running_loss = []
            for data, target in cv_loader:
                data, target = data.to(device), target.to(device)
                y_pred = model(data.float())
                loss = criterion(y_pred, target)
                running_loss.append(loss.item())
            cv_losses.append(sum(running_loss) / len(running_loss))
            print(f"[CV] epoch: {epoch:5}, loss: {cv_losses[-1]:10}")

    train_losses = np.array(train_losses)
    cv_losses = np.array(cv_losses)
    epochs = np.array([*range(1, len(train_losses) + 1)])
    plt.plot(epochs, train_losses)
    plt.plot(epochs, cv_losses)
    plt.legend(["Train Loss", "CV Loss"])
    plt.show()
    torch.save(model.state_dict(), 'geohotz_20k.pt')
        
if __name__ == '__main__':
    main()